{"cells": [{"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import pandas as pd\n", "import numpy as np\n", "import matplotlib.pyplot as plt\n", "import matplotlib.mlab as mlab"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import tensorflow as tf\n", "from keras.layers.core import flatten"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from keras.layers.pooling import MaxPooling2D\n", "from keras.models import Sequential, Model\n", "from keras.callbacks import EarlyStopping, Callback\n", "from tf.keras.layers import Dense, Dropout, Activation, Flatten, Lambda, ELU,GlobalAveragePooling2D, regularizers\n", "from keras.layers.convolutional import Convolution2D, Cropping2D, Conv2D\n", "from keras.layers.pooling import MaxPooling2D\n", "from keras.optimizers import adam\n", "from sklearn.utils import shuffle\n", "from keras.utils import np_utils"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import time, cv2, glob"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["global inputShape,size"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def kerasModel4():\n", "        model = Sequential()\n", "        model.add(Conv2D(16, (8, 8), strides=(4, 4), padding='valid', input_shape=(size,size,1)))\n", "        model.add(Activation('relu'))\n", "        model.add(Conv2D(32, (5, 5), padding=\"same\"))\n", "        model.add(Activation('relu'))\n", "        model.add(GlobalAveragePooling2D())\n", "        # model.add(Dropout(.2))\n", "        # model.add(Activation('relu'))\n", "        # model.add(Dense(1024))\n", "        # model.add(Dropout(.5))\n", "        model.add(Dense(512))\n", "        model.add(Dropout(.1))\n", "        model.add(Activation('relu'))\n", "        # model.add(Dense(256))\n", "        # model.add(Dropout(.5))\n", "        # model.add(Activation('relu'))\n", "        model.add(Dense(2))\n", "        model.add(Activation('softmax'))\n", "        return model"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["size=100"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": [" ## load Training data : pothole\n", "potholeTrainImages = glob.glob(\"C:/Users/anant/Desktop/pothole-and-plain-rode-images/My Dataset/train/Pothole/*.jpg\")\n", "potholeTrainImages.extend(glob.glob(\"C:/Users/anant/Desktop/pothole-and-plain-rode-images/My Dataset/train/Pothole/*.jpeg\"))\n", "potholeTrainImages.extend(glob.glob(\"C:/Users/anant/Desktop/pothole-and-plain-rode-images/My Dataset/train/Pothole/*.png\"))"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["train1 = [cv2.imread(img,0) for img in potholeTrainImages]\n", "for i in range(0,len(train1)):\n", "    train1[i] = cv2.resize(train1[i],(size,size))\n", "temp1 = np.asarray(train1)"]}, {"cell_type": "markdown", "metadata": {}, "source": [" ## load Training data : non-pothole"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["nonPotholeTrainImages = glob.glob(\"C:/Users/anant/Desktop/pothole-and-plain-rode-images/My Dataset/train/Plain/*.jpg\")\n", "# nonPotholeTrainImages.extend(glob.glob(\"C:/Users/anant/Desktop/pothole-and-plain-rode-images/My Dataset/train/Plain/*.jpeg\"))\n", "# nonPotholeTrainImages.extend(glob.glob(\"C:/Users/anant/Desktop/pothole-and-plain-rode-images/My Dataset/train/Plain/*.png\"))\n", "train2 = [cv2.imread(img,0) for img in nonPotholeTrainImages]\n", "# train2[train2 != np.array(None)]\n", "for i in range(0,len(train2)):\n", "    train2[i] = cv2.resize(train2[i],(size,size))\n", "temp2 = np.asarray(train2)"]}, {"cell_type": "markdown", "metadata": {}, "source": [" load Testing data : non-pothole"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["nonPotholeTestImages = glob.glob(\"C:/Users/anant/Desktop/pothole-and-plain-rode-images/My Dataset/test/Plain/*.jpg\")\n", "# nonPotholeTrainImages.extend(glob.glob(\"C:/Users/anant/Desktop/pothole-and-plain-rode-images/My Dataset/train/Plain/*.jpeg\"))\n", "# nonPotholeTrainImages.extend(glob.glob(\"C:/Users/anant/Desktop/pothole-and-plain-rode-images/My Dataset/train/Plain/*.png\"))\n", "test2 = [cv2.imread(img,0) for img in nonPotholeTestImages]\n", "# train2[train2 != np.array(None)]\n", "for i in range(0,len(test2)):\n", "    test2[i] = cv2.resize(test2[i],(size,size))\n", "temp4 = np.asarray(test2)"]}, {"cell_type": "markdown", "metadata": {}, "source": [" load Testing data : potholes"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["potholeTestImages = glob.glob(\"C:/Users/anant/Desktop/pothole-and-plain-rode-images/My Dataset/test/Pothole/*.jpg\")\n", "# nonPotholeTrainImages.extend(glob.glob(\"C:/Users/anant/Desktop/pothole-and-plain-rode-images/My Dataset/train/Plain/*.jpeg\"))\n", "# nonPotholeTrainImages.extend(glob.glob(\"C:/Users/anant/Desktop/pothole-and-plain-rode-images/My Dataset/train/Plain/*.png\"))\n", "test1 = [cv2.imread(img,0) for img in potholeTestImages]\n", "# train2[train2 != np.array(None)]\n", "for i in range(0,len(test1)):\n", "    test1[i] = cv2.resize(test1[i],(size,size))\n", "temp3 = np.asarray(test1)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["X_train = []\n", "X_train.extend(temp1)\n", "X_train.extend(temp2)\n", "X_train = np.asarray(X_train)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["X_test = []\n", "X_test.extend(temp3)\n", "X_test.extend(temp4)\n", "X_test = np.asarray(X_test)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["y_train1 = np.ones([temp1.shape[0]],dtype = int)\n", "y_train2 = np.zeros([temp2.shape[0]],dtype = int)\n", "y_test1 = np.ones([temp3.shape[0]],dtype = int)\n", "y_test2 = np.zeros([temp4.shape[0]],dtype = int)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(y_train1[0])\n", "print(y_train2[0])\n", "print(y_test1[0])\n", "print(y_test2[0])"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["y_train = []\n", "y_train.extend(y_train1)\n", "y_train.extend(y_train2)\n", "y_train = np.asarray(y_train)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["y_test = []\n", "y_test.extend(y_test1)\n", "y_test.extend(y_test2)\n", "y_test = np.asarray(y_test)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["X_train,y_train = shuffle(X_train,y_train)\n", "X_test,y_test = shuffle(X_test,y_test)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["X_train.reshape([-1,50,50,1])<br>\n", "X_test.reshape([-1,50,50,1])/"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["X_train = X_train.reshape(X_train.shape[0], size, size, 1)\n", "X_test = X_test.reshape(X_test.shape[0], size, size, 1)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["y_train = np_utils.to_categorical(y_train)\n", "y_test = np_utils.to_categorical(y_test)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(\"train shape X\", X_train.shape)\n", "print(\"train shape y\", y_train.shape)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["inputShape = (size, size, 1)\n", "model = kerasModel4()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["model.compile('adam', 'categorical_crossentropy', ['accuracy'])\n", "history = model.fit(X_train, y_train, epochs=500,validation_split=0.1)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["metrics = model.evaluate(X_test, y_test)\n", "for metric_i in range(len(model.metrics_names)):\n", "    metric_name = model.metrics_names[metric_i]\n", "    metric_value = metrics[metric_i]\n", "    print('{}: {}'.format(metric_name, metric_value))"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(\"Saving model weights and configuration file\")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["model.save('sample.h5')"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["model_json = model.to_json()\n", "with open(\"truesample.json\", \"w\") as json_file:\n", "    json_file.write(model_json)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["model.save_weights(\"truesample.h5\")\n", "print(\"Saved model to disk\")"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}